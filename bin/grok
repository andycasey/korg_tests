#!python
import argparse

# SME Library version: 5.22, linux

parser = argparse.ArgumentParser(description="Compare spectral synthesis codes")
parser.add_argument("file", type=str, help="Configuration file")
parser.add_argument("-v", dest="verbose", action="store_true", help="Verbose mode")
parser.add_argument("-o", "--output-file", type=str, default=None, help="Output file")
parser.add_argument("--skip", action="store_true", help="Skip completed syntheses")

args = parser.parse_args()

import os
import json
import sys
import yaml
import logging
import pickle
import numpy as np
import h5py
from shutil import rmtree

from grok.utils import get_logger, expand_path
from grok.photospheres import Photosphere
from grok.transitions import Transitions
from grok.synthesis import synthesize, AVAILABLE_METHODS

from grok.synthesis.turbospectrum.transitions import should_keep

#logger = get_logger(logging.DEBUG if args.verbose else logging.INFO)
logger = get_logger(logging.DEBUG)

with open(args.file, "r") as fp:
    config = yaml.load(fp, Loader=yaml.FullLoader)

class NumpyEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        return json.JSONEncoder.default(self, obj)


output_file = expand_path(args.output_file)
output_dir = os.path.dirname(output_file)
os.makedirs(output_dir, exist_ok=True)
logger.info(f"Output file: {output_file}")

output = h5py.File(output_file, "a")

pwd = os.path.dirname(args.file)

resolve_path = lambda path: path if os.path.exists(path) else os.path.join(pwd, path)

for comparison in config["comparisons"][::-1]:

    name = comparison["name"]
    logger.debug(f"Running experiment named {name}")

    lambdas = lambda_min, lambda_max, lambda_step = (
        comparison["wavelengths"]["min"],
        comparison["wavelengths"]["max"],
        comparison["wavelengths"]["step"]
    )

    photosphere_path = resolve_path(comparison["photosphere"])

    logger.debug(f"Loading photosphere from {photosphere_path}")
    photosphere = Photosphere.read(photosphere_path)

    try:
        methods = comparison["spectral_synthesis"].keys()
    except:
        logger.exception(f"No spectral synthesis codes listed to try in ``spectral_synthesis``")
        sys.exit(1)


    for method in methods:
        if method not in AVAILABLE_METHODS:
            logger.exception(f"Method '{method}' not one of the available methods: {', '.join(AVAILABLE_METHODS)}")
            sys.exit(1)

    default_consider_reasons = (0, )
    for method in methods:
        #output_path = os.path.join(output_dir, f"{name}-{method}.pkl")
        #if os.path.exists(output_path) and not args.clobber:
        #    logger.info(f"Output file {output_path} already exists. Skipping.")
        #    continue
        try:
            output[f"{name}/{method}"]
        except:
            None
        else:
            logger.info(f"Group '{name}/{method}' already exists. Skipping.")
            continue


        logger.debug(f"Preparing synthesis with {method}")

        options = {}

        if method == "moog":
            
            options = comparison["spectral_synthesis"][method]

            window = options.get("window", 2)

            # Handle chunking.
            n_chunks = options.get("n_chunks", None)
            if n_chunks is not None:
                options["n_chunks"] = n_chunks

            # Load transitions.
            transitions = []
            for path in comparison["transitions"]["paths"]:
                transitions.extend(Transitions.read(resolve_path(path)))

            corrected_isotope_path = comparison["transitions"].get("corrected_isotope_path", None)
            if corrected_isotope_path is not None:
                corrected_isotope_path = resolve_path(corrected_isotope_path)
                logger.debug(f"Reading in corrected isotope data from {corrected_isotope_path}")
                transitions = sorted(transitions, key=lambda t: t.lambda_air.value)

                ts_corrections = np.loadtxt(corrected_isotope_path, delimiter=",")
                assert len(transitions) == len(ts_corrections)
                for transition, correction in zip(transitions, ts_corrections):
                    lambda_air, e_lower, log_gf, gamma_rad = correction
                    assert np.isclose(transition.lambda_air.value, lambda_air)
                    transition.log_gf = log_gf

            # Exclude strong lines.
            input_transitions_format = comparison["transitions"].get("input_transitions_format", None)

            if "strong_path" in comparison["transitions"]:
                strong_transitions = Transitions.read(
                    resolve_path(comparison["transitions"]["strong_path"]),
                    format=input_transitions_format
                )
                transitions = Transitions([t for t in transitions if t not in strong_transitions])
                options["strong_transitions"] = strong_transitions

            # Handle transition restrictions.
            max_transitions = options.get("max_transitions", None)
            if max_transitions is not None:

                logger.info(f"There are {len(transitions)} transitions that were read in")
                consider_reasons = options.get("restrict_to_keep_on_reasons", default_consider_reasons)
                in_window = lambda t: (lambda_max + window) >= t.lambda_vacuum.value >= (lambda_min - window)
                keep = lambda t: should_keep(t, consider_reasons) and in_window(t)

                transitions = Transitions(list(filter(keep, transitions)))
                N = len(transitions)
                logger.info(f"There are now {N} transitions after considering those within window, and with keep_on_reasons {consider_reasons}")

                if N > max_transitions:
                    logger.debug(f"Input transitions exceeds maximum allowed for {method}: {N} > {max_transitions}")

                    restrict_to = options.get("restrict_to_strongest_transitions", None)
                    if restrict_to is not None:
                        logger.debug(f"Restricting to {restrict_to} strongest transitions")
                        restrict_to = list(map(tuple, restrict_to))
                        restrict_on = lambda t: t.species.atoms in restrict_to

                        teff = photosphere.meta["teff"]
                        def strength(t, teff):
                            return t.log_gf - t.E_lower.value * (5040/teff) + np.log(t.lambda_air.value)

                        non_restricted, S = 0, []
                        for t in transitions:
                            if restrict_on(t):
                                S.append(strength(t, teff))
                            else:
                                non_restricted += 1

                        if non_restricted > max_transitions:
                            raise RuntimeError(f"Need to restrict on something else: there are {non_restricted} transitions (>{max_transitions})")
                        
                        min_S = np.sort(S)[-max_transitions + non_restricted]

                        transitions = Transitions([t for t in transitions if not restrict_on(t) or strength(t, teff) >= min_S])
                        logger.info(f"Now there are {len(transitions)} after restricting on strength")

        elif method == "sme":
            input_transitions_format = comparison["transitions"].get("input_transitions_format", "vald")
            if input_transitions_format == "vald":
                transitions = list(map(resolve_path, comparison["transitions"]["paths"]))

            else:
                # Load them in.
                transitions = []
                for path in comparison["transitions"]["paths"]:
                    transitions.extend(Transitions.read(resolve_path(path)))
                
                corrected_isotope_path = comparison["transitions"].get("corrected_isotope_path", None)
                if corrected_isotope_path is not None:
                    corrected_isotope_path = resolve_path(corrected_isotope_path)
                    logger.debug(f"Reading in corrected isotope data from {corrected_isotope_path}")
                    transitions = sorted(transitions, key=lambda t: t.lambda_air.value)

                    ts_corrections = np.loadtxt(corrected_isotope_path, delimiter=",")
                    assert len(transitions) == len(ts_corrections)
                    for transition, correction in zip(transitions, ts_corrections):
                        lambda_air, e_lower, log_gf, gamma_rad = correction
                        assert np.isclose(transition.lambda_air.value, lambda_air)
                        transition.log_gf = log_gf

                transitions = Transitions(transitions)

                    
            options.update(comparison["spectral_synthesis"]["sme"] or {})

        elif method == "turbospectrum":
            # Just supply transitions as paths
            transitions = list(map(resolve_path, comparison["transitions"]["paths"]))
            options.update(comparison["spectral_synthesis"][method] or {})
            options["input_transitions_format"] = comparison["transitions"].get("input_transitions_format", None)

        elif method == "korg":
            # Just supply transitions as paths
            transitions = list(map(resolve_path, comparison["transitions"]["paths"]))
            options.update(comparison["spectral_synthesis"][method] or {})

        else:
            raise ValueError(f"Unknown method: {method}")

        logger.info(f"Executing {method} with options: {options}")
        try:
            spectrum, timing, meta = synthesize(
                photosphere,
                transitions,
                method=method,
                lambdas=lambdas,
                options=options
            )
        except:
            logger.exception(f"Exception occurred when executing {method} with options: {options}")
            raise
        else:
            logger.info("Done.")
            try:
                logger.debug(f"Standard output:\n{meta.pop('stdout')}")
            except:
                None
            try:
                logger.debug(f"Standard error:\n{meta.pop('stderr')}")
            except:
                None
            try:
                logger.debug(f"Timing for {method}: {json.dumps(timing, indent=4)}")
            except:
                logger.exception(f"Could not JSON dump timing array for {method}: {meta}")
                        
            # Save the outputs.
            try:
                group = output[name]
            except:
                group = output.create_group(name)
            
            try:
                sub_group = group[method]
            except:
                sub_group = group.create_group(method)
            
            # Store the spectra.
            for k, v in spectrum.items():
                sub_group.create_dataset(k, data=v)
            # And timing attributes.
            sub_group.attrs.update(timing)

            # TODO: store opacities from SME?
            '''
            outputs = (spectrum, timing, meta, options)
            with open(output_path, "wb") as fp:
                pickle.dump(outputs, fp)

            logger.info(f"Outputs of {name} written to {output_path}")
            '''
            print(f"Directory is {meta.get('dir', None)}")
            # Clean up directory.
            if meta.get("dir", None) is not None:
                logger.info(f"Removing directory {meta['dir']}")
                rmtree(meta["dir"])


output.close()