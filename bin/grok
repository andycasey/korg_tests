#!python
import argparse

parser = argparse.ArgumentParser(description="Compare spectral synthesis codes")
parser.add_argument("file", type=str, help="Configuration file")
parser.add_argument("-v", dest="verbose", action="store_true", help="Verbose mode")
parser.add_argument("-o", "--output-dir", type=str, default=None, help="Output directory")

args = parser.parse_args()

import os
import json
import sys
import yaml
import logging
import pickle
import numpy as np

from grok.utils import get_logger, expand_path
from grok.photospheres import Photosphere
from grok.transitions import Transitions
from grok.synthesis import synthesize, AVAILABLE_METHODS

from grok.synthesis.turbospectrum.transitions import should_keep

#logger = get_logger(logging.DEBUG if args.verbose else logging.INFO)
logger = get_logger(logging.DEBUG)

with open(args.file, "r") as fp:
    config = yaml.load(fp, Loader=yaml.FullLoader)

class NumpyEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        return json.JSONEncoder.default(self, obj)


output_dir = args.output_dir or f"."
output_dir = expand_path(output_dir)
os.makedirs(output_dir, exist_ok=True)
logger.info(f"Output directory: {output_dir}")

pwd = os.path.dirname(args.file)

resolve_path = lambda path: path if os.path.exists(path) else os.path.join(pwd, path)

for comparison in config["comparisons"]:

    name = comparison["name"]
    logger.debug(f"Running experiment named {name}")

    lambdas = lambda_min, lambda_max, lambda_step = (
        comparison["wavelengths"]["min"],
        comparison["wavelengths"]["max"],
        comparison["wavelengths"]["step"]
    )

    photosphere_path = resolve_path(comparison["photosphere"])

    logger.debug(f"Loading photosphere from {photosphere_path}")
    photosphere = Photosphere.read(photosphere_path)

    try:
        methods = comparison["spectral_synthesis"].keys()
    except:
        logger.exception(f"No spectral synthesis codes listed to try in ``spectral_synthesis``")
        sys.exit(1)


    for method in methods:
        if method not in AVAILABLE_METHODS:
            logger.exception(f"Method '{method}' not one of the available methods: {', '.join(AVAILABLE_METHODS)}")
            sys.exit(1)


    default_consider_reasons = (0, 1, 2, 3, 4)
    for method in methods:

        logger.debug(f"Preparing synthesis with {method}")

        options = {}

        if method == "moog":
            
            options = comparison["spectral_synthesis"][method]

            window = options.get("window", 2)

            # Handle chunking.
            n_chunks = options.get("n_chunks", None)
            if n_chunks is not None:
                options["n_chunks"] = n_chunks

            # Load transitions.
            transitions = []
            for path in comparison["transitions"]["paths"]:
                transitions.extend(Transitions.read(resolve_path(path)))

            corrected_isotope_path = comparison["transitions"].get("corrected_isotope_path", None)
            if corrected_isotope_path is not None:
                corrected_isotope_path = resolve_path(corrected_isotope_path)
                logger.debug(f"Reading in corrected isotope data from {corrected_isotope_path}")
                transitions = sorted(transitions, key=lambda t: t.lambda_air.value)

                ts_corrections = np.loadtxt(corrected_isotope_path, delimiter=",")
                assert len(transitions) == len(ts_corrections)
                for transition, correction in zip(transitions, ts_corrections):
                    lambda_air, e_lower, log_gf, gamma_rad = correction
                    assert np.isclose(transition.lambda_air.value, lambda_air)
                    transition.log_gf = log_gf

            # Exclude strong lines.
            if "strong_path" in comparison["transitions"]:
                strong_transitions = Transitions.read(resolve_path(comparison["transitions"]["strong_path"]))
                transitions = Transitions([t for t in transitions if t not in strong_transitions])
                options["strong_transitions"] = strong_transitions

            # Handle transition restrictions.
            max_transitions = options.get("max_transitions", None)
            if max_transitions is not None:

                logger.info(f"There are {len(transitions)} transitions that were read in")
                consider_reasons = options.get("restrict_to_keep_on_reasons", default_consider_reasons)
                in_window = lambda t: (lambda_max + window) >= t.lambda_vacuum.value >= (lambda_min - window)
                keep = lambda t: should_keep(t, consider_reasons) and in_window(t)

                transitions = Transitions(list(filter(keep, transitions)))
                N = len(transitions)
                logger.info(f"There are now {N} transitions after considering those within window, and with keep_on_reasons {consider_reasons}")

                if N > max_transitions:
                    logger.debug(f"Input transitions exceeds maximum allowed for {method}: {N} > {max_transitions}")

                    restrict_to = options.get("restrict_to_strongest_transitions", None)
                    if restrict_to is not None:
                        logger.debug(f"Restricting to {restrict_to} strongest transitions")
                        restrict_to = list(map(tuple, restrict_to))
                        restrict_on = lambda t: t.species.atoms in restrict_to

                        teff = photosphere.meta["teff"]
                        def strength(t, teff):
                            return t.log_gf - t.E_lower.value * (5040/teff) + np.log(t.lambda_air.value)

                        non_restricted, S = 0, []
                        for t in transitions:
                            if restrict_on(t):
                                S.append(strength(t, teff))
                            else:
                                non_restricted += 1

                        if non_restricted > max_transitions:
                            raise RuntimeError(f"Need to restrict on something else: there are {non_restricted} transitions (>{max_transitions})")
                        
                        min_S = np.sort(S)[-max_transitions + non_restricted]

                        transitions = Transitions([t for t in transitions if not restrict_on(t) or strength(t, teff) >= min_S])
                        logger.info(f"Now there are {len(transitions)} after restricting on strength")

        elif method == "sme":
            input_transitions_format = comparison["transitions"].get("input_transitions_format", "vald")
            if input_transitions_format == "vald":
                transitions = list(map(resolve_path, comparison["transitions"]["paths"]))

            else:
                # Load them in.
                transitions = []
                for path in comparison["transitions"]["paths"]:
                    transitions.extend(Transitions.read(resolve_path(path)))
                
                corrected_isotope_path = comparison["transitions"].get("corrected_isotope_path", None)
                if corrected_isotope_path is not None:
                    corrected_isotope_path = resolve_path(corrected_isotope_path)
                    logger.debug(f"Reading in corrected isotope data from {corrected_isotope_path}")
                    transitions = sorted(transitions, key=lambda t: t.lambda_air.value)

                    ts_corrections = np.loadtxt(corrected_isotope_path, delimiter=",")
                    assert len(transitions) == len(ts_corrections)
                    for transition, correction in zip(transitions, ts_corrections):
                        lambda_air, e_lower, log_gf, gamma_rad = correction
                        assert np.isclose(transition.lambda_air.value, lambda_air)
                        transition.log_gf = log_gf

                transitions = Transitions(transitions)

                    
            options.update(comparison["spectral_synthesis"]["sme"] or {})

        elif method in ("korg", "turbospectrum"):
            # Just supply transitions as paths
            transitions = list(map(resolve_path, comparison["transitions"]["paths"]))
            options.update(comparison["spectral_synthesis"][method] or {})

        else:
            raise ValueError(f"Unknown method: {method}")

        logger.info(f"Executing {method} with options: {options}")
        try:
            spectrum, timing, meta = synthesize(
                photosphere,
                transitions,
                method=method,
                lambdas=lambdas,
                options=options
            )
        except:
            logger.exception(f"Exception occurred when executing {method} with options: {options}")
            raise
        else:
            logger.info("Done.")
            try:
                logger.debug(f"Standard output:\n{meta.pop('stdout')}")
            except:
                None
            try:
                logger.debug(f"Standard error:\n{meta.pop('stderr')}")
            except:
                None
            try:
                logger.debug(f"Timing for {method}: {json.dumps(timing, indent=4)}")
            except:
                logger.exception(f"Could not JSON dump timing array for {method}: {meta}")
            
            # Save the outputs.
            outputs = (spectrum, timing, meta, options)
            output_path = os.path.join(output_dir, f"{name}-{method}.pkl")
            with open(output_path, "wb") as fp:
                pickle.dump(outputs, fp)

            logger.info(f"Outputs of {name} written to {output_path}")
